{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa5b03fd-bf83-4cd5-acce-683e45e61056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import PPOConfig, PPOTrainer\n",
    "import utils\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    BertModel,\n",
    "    pipeline,\n",
    "    AutoModelForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "import yaml\n",
    "import getpass\n",
    "import wandb\n",
    "from typing import Dict, Any\n",
    "import torch as t\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "from tqdm import tqdm\n",
    "import trl\n",
    "import importlib\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ac7b1f-fa4b-4715-b64e-fbd10378566b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/workspace/DPO-RLHF_generalization/utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS BLOCK IF YOU CHANGE UTILS BUT DON'T WANT TO RERUN WHOLE NOTEBOOK\n",
    "\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23e7a2c-b76c-454a-86c9-e81fabd7a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_fn(\n",
    "    model: AutoModel,\n",
    "    reward_tokenizer: AutoTokenizer,\n",
    "    prompt_text: list[str],\n",
    "    response_text: list[str],\n",
    "    device: str,\n",
    ") -> list[t.FloatTensor]:\n",
    "    \"\"\"Compute the reward for a given response to a prompt.\n",
    "\n",
    "    Args:\n",
    "        model (AutoModel): Huggingface model.\n",
    "        tokenizer (AutoTokenizer): Huggingface tokenizer.\n",
    "        prompt_text (list[str]): List of strings representing the prompt.\n",
    "        response_text (list[str]): List of strings representing the response.\n",
    "        device (str, optional): Device to run the model on. Defaults to 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        list[float]: A list of floats representing the reward.\n",
    "\n",
    "    \"\"\"\n",
    "    with t.no_grad():\n",
    "        encoding = reward_tokenizer(\n",
    "            prompt_text,\n",
    "            response_text,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        encoding = encoding.to(device)\n",
    "\n",
    "        logits = model(**encoding).logits\n",
    "        # scores = logits.cpu().numpy().flatten().tolist()\n",
    "\n",
    "        return logits\n",
    "\n",
    "def setup_logging(hps: Dict[str, Any], log_wandb):\n",
    "    # Choose logging and checkpoint saving directory\n",
    "    logdir = utils.choose_log_dir(\n",
    "        f\"{utils.run_dir}/{hps['dataset_name']}/training/{hps['training_algorithm']}\",\n",
    "        debug=hps[\"debug\"],\n",
    "    )\n",
    "\n",
    "    # Add a couple of keys to the hps object and save it as a yaml file\n",
    "    hps[\"logdir\"] = logdir\n",
    "\n",
    "    hps[\"training_kwargs\"][\"run_name\"] = \"/\".join(logdir.split(\"/\")[-2:])\n",
    "    hps[\"user\"] = getpass.getuser()\n",
    "    hps[\"tags\"] += [\n",
    "        hps[\"dataset\"][\"name\"],\n",
    "        \"training\",\n",
    "        hps[\"training_algorithm\"],\n",
    "    ]\n",
    "    with open(f\"{logdir}/hps.yaml\", \"w\") as f:\n",
    "        yaml.dump(hps, f)\n",
    "\n",
    "    # If not in debug mode, setup wandb logging\n",
    "    if not hps[\"debug\"] or log_wandb:\n",
    "        wandb.init(\n",
    "            project=\"dpo_rlhf_generalization\",\n",
    "            dir=logdir,\n",
    "            name=hps[\"training_kwargs\"][\"run_name\"],\n",
    "            config=utils.wandb_configify(hps),\n",
    "            tags=hps[\"tags\"],\n",
    "            save_code=True,\n",
    "            settings=wandb.Settings(code_dir=\".\"),\n",
    "        )\n",
    "\n",
    "    print(f\"Hyperparameters:\\n{hps}\\n\")\n",
    "    return logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07248ae6-67db-4a95-bb1e-4b44756abd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5630ca-3e6d-4e8a-8418-f2b2c13b2ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    queries = [item['query'] for item in batch]\n",
    "\n",
    "    max_length = max(len(ids) for ids in input_ids)\n",
    "    input_ids = [[tokenizer.pad_token_id] * (max_length - len(ids)) + ids for ids in input_ids]\n",
    "\n",
    "    input_ids = t.tensor(input_ids)\n",
    "    return {'input_ids': input_ids, 'queries': queries}\n",
    "    \n",
    "def tokenize(sample):\n",
    "    # sample[\"input_ids\"] = tokenizer.encode(\n",
    "    #     sample[\"query\"],\n",
    "    # )\n",
    "\n",
    "    sample[\"input_ids\"] = tokenizer(\n",
    "        sample[\"query\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt',\n",
    "    )['input_ids']\n",
    "    sample[\"input_ids\"] = sample['input_ids'].squeeze(0)\n",
    "    return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51683cdd-2765-46f0-b307-1da6a5444681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS BLOCK IF YOU CHANGE YAML FILE BUT DON'T WANT TO RERUN WHOLE NOTEBOOK\n",
    "\n",
    "args = 'hyperparams/rlhf.yaml'\n",
    "with open(\n",
    "    args\n",
    ") as f:\n",
    "    hps = yaml.load(f, Loader=yaml.FullLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e1b44-7d0e-4292-8801-c85c323b4ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "tokenizer, model = utils.load_model(\n",
    "    hps[\"model\"],\n",
    "    reward_model=False,\n",
    "    eval=False,\n",
    "    quantized=True,\n",
    "    bnb_config=bnb_config,\n",
    ")\n",
    "# tokenizer.padding_side = 'left'\n",
    "\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "model = trl.AutoModelForCausalLMWithValueHead.from_pretrained(model)\n",
    "\n",
    "# load reward model\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(hps[\"calibrated_model_path\"])\n",
    "reward_model = reward_model.to(t.device(\"cuda:0\")).eval()\n",
    "tokenizer_reward = AutoTokenizer.from_pretrained(hps[\"calibrated_model_path\"])\n",
    "reward_model.config.pad_token_id = tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2413e9e4-d68a-45bb-b94d-e1733cfc2eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process dataset. Make eval set smaller for speed reasons.\n",
    "dataset = utils.load_dataset(tokenizer, **hps[\"dataset\"], debug=True)\n",
    "test_size = min(len(dataset[\"test\"]), 2_000)\n",
    "dataset[\"test\"] = dataset[\"test\"].shuffle(seed=42).select(range(test_size))\n",
    "\n",
    "dataset = dataset.rename_column(\"prompt\", \"query\")\n",
    "dataset = dataset.map(tokenize, batched=False)\n",
    "dataset = dataset.remove_columns([\"chosen\", \"rejected\"])\n",
    "\n",
    "print(\"Dataset size:\", len(dataset['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1a9b4-67b0-43ab-b012-06ffa0578e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep debug runs short\n",
    "hps[\"debug\"] = True\n",
    "# if hps[\"debug\"]:\n",
    "#     hps[\"training_kwargs\"][\"max_steps\"] = 5\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    # **hps[\"training_kwargs\"]\n",
    "    batch_size=hps[\"training_kwargs\"][\"batch_size\"],\n",
    "    gradient_accumulation_steps=hps[\"training_kwargs\"][\"gradient_accumulation_steps\"],\n",
    "    mini_batch_size=hps[\"training_kwargs\"][\"mini_batch_size\"],\n",
    "    learning_rate=float(hps[\"training_kwargs\"][\"learning_rate\"]),\n",
    "    log_with=\"wandb\"\n",
    ")\n",
    "\n",
    "# sent_kwargs = {\n",
    "#     \"return_all_scores\": True,\n",
    "#     \"function_to_apply\": \"none\",\n",
    "#     \"batch_size\": 4,\n",
    "# }\n",
    "t.cuda.empty_cache()\n",
    "\n",
    "ppo_trainer = PPOTrainer(\n",
    "    model=model,\n",
    "    config=config,\n",
    "    dataset=dataset['train'],\n",
    "    tokenizer=tokenizer,  \n",
    ")\n",
    "\n",
    "dl = ppo_trainer.prepare_dataloader(dataset['train'], data_collator=custom_collate)\n",
    "num_epochs = 2\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 20,\n",
    "    # \"temperature\": 0.7,\n",
    "    \"top_k\": 0,\n",
    "    \"top_p\": .9,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"max_new_tokens\": 100,\n",
    "}\n",
    "\n",
    "# ppo_trainer.train(dl, num_epochs = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e02958-968c-4127-a235-fc9050e1e23f",
   "metadata": {},
   "source": [
    "allocated_memory = t.cuda.memory_allocated()\n",
    "print(f\"memory allocated: {allocated_memory / (2**30)} / ~80 GBs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3be0e1-099c-41a3-97eb-545685cf6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting logging\n",
    "# logdir = setup_logging(hps, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63af104-f1dd-40f5-aa39-acf0eb7209d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in tqdm(range(epochs), \"epoch: \"):\n",
    "    for batch in tqdm(ppo_trainer.dataloader):\n",
    "        allocated_memory = t.cuda.memory_allocated()\n",
    "        print(f\"memory allocated: {allocated_memory / (2**30)}\")\n",
    "\n",
    "        t.cuda.empty_cache()\n",
    "\n",
    "        query_tensors = t.stack(batch['input_ids'],1)\n",
    "        # print(query_tensors.shape)\n",
    "        query_tensors = [tensor.view(-1) for tensor in query_tensors]\n",
    "        #### Get response from SFTModel\n",
    "        response_tensors = ppo_trainer.generate(query_tensors, **generation_kwargs)\n",
    "\n",
    "        batch[\"response\"] = [\n",
    "            tokenizer.decode(r.squeeze()) for r in response_tensors\n",
    "        ]\n",
    "        print(batch['query'])\n",
    "        print(batch['response'])\n",
    "        #### Compute reward score\n",
    "        chosen_scores = list(reward_fn(reward_model, tokenizer_reward, batch[\"query\"], batch[\"response\"], device).flatten())\n",
    "        t.cuda.empty_cache()\n",
    "        #### Run PPO step\n",
    "\n",
    "        for (i, response) in enumerate(response_tensors):\n",
    "            if len(response) == 1:\n",
    "                chosen_scores[i] -= 5\n",
    "\n",
    "        print(chosen_scores)\n",
    "        \n",
    "        stats = ppo_trainer.step(query_tensors, response_tensors, chosen_scores)\n",
    "        ppo_trainer.log_stats(stats, batch, chosen_scores)\n",
    "\n",
    "        # wandb.log(stats)\n",
    "\n",
    "#### Save model\n",
    "ppo_trainer.save_pretrained(\"my_ppo_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1abe4f31-6ab5-481d-b608-f3ee1e9cffc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'response'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresponse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'response'"
     ]
    }
   ],
   "source": [
    "batch['response']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc9f69a-a564-484c-842d-5862a80c837f",
   "metadata": {},
   "source": [
    "# ignore below? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f9244-ae06-4fed-acc2-79d6ae2c1cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(ppo_trainer.dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "914933be-e4b3-4cea-bf70-77e9bcf650f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train']['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a331f4a-c9df-4049-8eaf-1f8ea84f618e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mbatch\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "len(batch['queries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfa7a81e-6f5b-436e-a6d7-15d99490f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tensors = batch[\"input_ids\"]\n",
    "# print(query_tensors.shape)\n",
    "query_tensors = [tensor.view(-1) for tensor in query_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1f607dc-0690-46e9-b0c5-e17136940056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Get response from SFTModel\n",
    "response_tensors = ppo_trainer.generate(query_tensors, **generation_kwargs)\n",
    "\n",
    "batch[\"response\"] = [\n",
    "    tokenizer.decode(r.squeeze()) for r in response_tensors\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dad4401-8147-41e3-80bb-2e6547ad652b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.4236, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "#### Compute reward score\n",
    "# texts = [q + r for q, r in zip(batch[\"queries\"], batch[\"response\"])]\n",
    "chosen_scores = list(reward_fn(reward_model, tokenizer, batch[\"queries\"], batch[\"response\"], device).flatten())\n",
    "# rewards = [t.tensor(output[1][\"score\"]) for output in pipe_outputs]\n",
    "print(chosen_scores)\n",
    "\n",
    "t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cff73c3-e43b-45f5-bc59-45ac78d85249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 11 09:36:52 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              68W / 400W |  81013MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc8fab6c-eb05-4f3a-bba8-ddefcb5b9d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Run PPO step\n",
    "stats = ppo_trainer.step(query_tensors, response_tensors, chosen_scores)\n",
    "ppo_trainer.log_stats(stats, batch, chosen_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6ec74-b1c6-4761-9fe8-0e9f6ca8eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_scores = list(reward_fn(reward_model, tokenizer, batch[\"queries\"], batch[\"response\"], device).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d72d20-b922-474f-a0e5-02b4ff3dd69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ppo_trainer.step(query_tensors, response_tensors, chosen_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c8ff0-e797-4567-b25a-aec272b9c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # I think PPO trainer fine tunes already, so we don't need this\n",
    "#     peft_config = LoraConfig(\n",
    "    \n",
    "#     task_type=TaskType.CAUSAL_LM, inference_mode=False, r=32, lora_alpha=16, lora_dropout=0.1,\n",
    "# ) # create LoRA config for the finetuning\n",
    "\n",
    "#     model = get_peft_model(model, peft_config) # create a model ready for LoRA finetuning\n",
    "\n",
    "#     tokenizer.pad_token = tokenizer.eos_token # need this because tokenizer doesn't have default padding\n",
    "\n",
    "#     # fine tune!\n",
    "#     training_args = TrainingArguments(\n",
    "#         output_dir=\"./results\",\n",
    "#         num_train_epochs=3,\n",
    "#         per_device_train_batch_size=1,\n",
    "#         per_device_eval_batch_size=2,\n",
    "#         warmup_steps=500,\n",
    "#         weight_decay=0.01,\n",
    "#         logging_dir=logdir,\n",
    "#         logging_steps=10,\n",
    "#         learning_rate = 1e-3,\n",
    "#     )\n",
    "\n",
    "#     trainer = Trainer(\n",
    "#         model=model,\n",
    "#         args=training_args,\n",
    "#         train_dataset=dataset,\n",
    "#     )\n",
    "#     trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

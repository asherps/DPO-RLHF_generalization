{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0a52a8-ecb9-433e-86aa-cf4037843d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import PPOConfig, PPOTrainer\n",
    "import utils\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    BertModel,\n",
    "    pipeline,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "import yaml\n",
    "import getpass\n",
    "import wandb\n",
    "from typing import Dict, Any\n",
    "import torch as t\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "from tqdm import tqdm\n",
    "import trl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import datasets\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57225e90-47c8-4620-a357-adc1b71772ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 10 23:43:57 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  | 00000000:2D:00.0 Off |                    0 |\n",
      "| N/A   25C    P0              41W / 300W |     18MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dc8bef6-3432-4104-8bc7-ddc99bb5bcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test0: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90346d114fa4f4cb5987126529c370a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at mistralai/Mistral-7B-v0.1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1: 14771847168\n"
     ]
    }
   ],
   "source": [
    "test_counter = 0\n",
    "device = \"cuda\"\n",
    "\n",
    "print(f\"test{test_counter}: {t.cuda.memory_allocated()}\")\n",
    "test_counter += 1\n",
    "\n",
    "reward_model_path = \"./drive/root/project_data/calibrated_alignment/runs/instruct/training/reward_model/run_3/checkpoints/checkpoint-4000\"\n",
    "\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(reward_model_path, torch_dtype=t.bfloat16,num_labels=1).eval()\n",
    "reward_model = reward_model.to(device)\n",
    "\n",
    "\n",
    "reward_model.config.pad_token_id = reward_model.config.eos_token_id\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(reward_model_path,)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "reward_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "dataset_info = {\n",
    "    \"name\": \"Anthropic/hh-rlhf\",\n",
    "    \"data_dir\": \"default\" \n",
    "}\n",
    "\n",
    "print(f\"test{test_counter}: {t.cuda.memory_allocated()}\")\n",
    "test_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15efac89-804d-4b41-9a76-59c9a0a75883",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_ids_chosen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reward_model(\u001b[43minput_ids_chosen\u001b[49m, attention_mask_chosen)\u001b[38;5;241m.\u001b[39mlogits\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_ids_chosen' is not defined"
     ]
    }
   ],
   "source": [
    "reward_model(input_ids_chosen, attention_mask_chosen).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79abeabd-d685-477f-8bd8-e6d21b3e1232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1094],\n",
       "        [-1.8906],\n",
       "        [-2.0156],\n",
       "        [-1.6719],\n",
       "        [-1.6094],\n",
       "        [-2.1562],\n",
       "        [-1.4297],\n",
       "        [-1.5938],\n",
       "        [-0.5234],\n",
       "        [-1.2891],\n",
       "        [-2.3594],\n",
       "        [-2.1562],\n",
       "        [-1.1875],\n",
       "        [-1.5312],\n",
       "        [-2.2188],\n",
       "        [-1.7031],\n",
       "        [-1.0078],\n",
       "        [-2.2188],\n",
       "        [-0.4785],\n",
       "        [-1.0859],\n",
       "        [-1.2266],\n",
       "        [-1.3438],\n",
       "        [-1.1094],\n",
       "        [-0.7734],\n",
       "        [-1.7734],\n",
       "        [-1.6875],\n",
       "        [-1.6562],\n",
       "        [-1.0234],\n",
       "        [-0.3340],\n",
       "        [-0.6250],\n",
       "        [-2.0938],\n",
       "        [-1.4141],\n",
       "        [-1.5312],\n",
       "        [-1.6094],\n",
       "        [-1.7109],\n",
       "        [-0.3730],\n",
       "        [-1.2578],\n",
       "        [-1.4375],\n",
       "        [-1.5938],\n",
       "        [-1.8828],\n",
       "        [-2.0625],\n",
       "        [-1.7266],\n",
       "        [-1.1250],\n",
       "        [-1.7188],\n",
       "        [-1.3203],\n",
       "        [-1.8594],\n",
       "        [-2.4375],\n",
       "        [-1.4219],\n",
       "        [-1.1797],\n",
       "        [-1.3906]], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_model(input_ids_chosen, attention_mask_chosen).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a9868fc-a503-4c5e-991e-5fccd2629e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_for_reward_trainer(sample):\n",
    "    # print(sample)\n",
    "    chosen = [p + c for p, c in zip(sample[\"prompt\"], sample[\"chosen\"])]\n",
    "    chosen_inputs = tokenizer(\n",
    "        chosen,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=1536,\n",
    "    )\n",
    "\n",
    "    rejected = [p + r for p, r in zip(sample[\"prompt\"], sample[\"rejected\"])]\n",
    "    rejected_inputs = tokenizer(\n",
    "        rejected,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=1536,\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids_chosen\": chosen_inputs[\"input_ids\"],\n",
    "        \"attention_mask_chosen\": chosen_inputs[\"attention_mask\"],\n",
    "        \"input_ids_rejected\": rejected_inputs[\"input_ids\"],\n",
    "        \"attention_mask_rejected\": rejected_inputs[\"attention_mask\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afef3ace-1718-4e17-a317-59f252b4ac54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6016, -4.6875],\n",
       "        [ 1.3359, -4.9688],\n",
       "        [ 0.9375, -4.6562],\n",
       "        [-0.9336, -4.6875],\n",
       "        [ 0.0791, -6.7812],\n",
       "        [ 1.2266, -4.3750],\n",
       "        [ 1.8750, -5.1875],\n",
       "        [ 1.0781, -4.4688],\n",
       "        [ 3.8125, -5.8750],\n",
       "        [ 0.4219, -4.8125],\n",
       "        [ 1.3281, -4.5625],\n",
       "        [ 0.7539, -6.0000],\n",
       "        [ 1.2891, -3.8438],\n",
       "        [ 0.9180, -3.9844],\n",
       "        [ 0.9648, -4.2188],\n",
       "        [ 2.1562, -4.0938],\n",
       "        [ 1.0938, -4.5625],\n",
       "        [ 1.2344, -4.0625],\n",
       "        [ 2.7656, -6.0625],\n",
       "        [ 1.3203, -4.4375],\n",
       "        [ 2.7188, -5.9375],\n",
       "        [ 0.9688, -4.6562],\n",
       "        [ 2.1094, -4.9062],\n",
       "        [ 3.8281, -5.3125],\n",
       "        [ 3.9375, -6.1250],\n",
       "        [ 2.6094, -5.3125],\n",
       "        [ 0.6055, -4.5938],\n",
       "        [ 2.2188, -5.4062],\n",
       "        [ 2.0938, -5.2500],\n",
       "        [ 2.9062, -5.5000],\n",
       "        [ 0.6562, -3.7500],\n",
       "        [ 1.1406, -3.8281],\n",
       "        [ 2.3281, -5.4375],\n",
       "        [ 4.0312, -5.8750],\n",
       "        [ 1.0938, -5.2812],\n",
       "        [ 2.4219, -5.8125],\n",
       "        [ 1.1484, -4.9375],\n",
       "        [ 2.8125, -6.0000],\n",
       "        [ 1.2266, -5.0000],\n",
       "        [ 2.7344, -5.7500],\n",
       "        [ 1.6172, -4.5625],\n",
       "        [ 2.0938, -5.3750],\n",
       "        [ 1.2656, -4.8125],\n",
       "        [ 3.3906, -5.5312],\n",
       "        [ 0.4473, -4.4375],\n",
       "        [ 1.3281, -4.1562],\n",
       "        [ 1.0703, -3.7656],\n",
       "        [ 2.9531, -5.6562],\n",
       "        [ 2.4688, -5.4062],\n",
       "        [ 3.5156, -5.6562]], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_chosen.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fbbf0c4-7242-44d0-9904-b540a965c24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7734, -4.7500],\n",
       "        [ 0.9766, -4.0938],\n",
       "        [ 1.0000, -4.2812],\n",
       "        [-0.5820, -3.9688],\n",
       "        [ 4.0938, -6.3125],\n",
       "        [ 1.0391, -4.6562],\n",
       "        [ 1.7500, -4.8125],\n",
       "        [ 1.2344, -4.2812],\n",
       "        [ 3.6562, -5.9375],\n",
       "        [ 0.6328, -4.4062],\n",
       "        [ 1.5859, -4.6562],\n",
       "        [ 1.2734, -6.2500],\n",
       "        [ 0.1680, -4.4062],\n",
       "        [ 0.0203, -3.7656],\n",
       "        [ 1.5469, -4.0312],\n",
       "        [ 1.8281, -4.7188],\n",
       "        [ 1.6797, -4.5938],\n",
       "        [ 1.2656, -4.3125],\n",
       "        [ 2.6094, -6.0938],\n",
       "        [ 1.1016, -4.4688],\n",
       "        [ 2.7031, -5.6250],\n",
       "        [ 1.0078, -4.6562],\n",
       "        [ 1.8125, -5.5000],\n",
       "        [ 3.5156, -5.3125],\n",
       "        [ 4.1250, -6.0625],\n",
       "        [ 2.1406, -5.1250],\n",
       "        [ 0.6055, -4.5625],\n",
       "        [ 2.6875, -5.4688],\n",
       "        [ 2.4062, -5.3438],\n",
       "        [ 1.6953, -6.4688],\n",
       "        [ 1.0859, -4.0938],\n",
       "        [ 1.2656, -4.5938],\n",
       "        [ 3.6094, -5.0312],\n",
       "        [ 4.0312, -4.8438],\n",
       "        [ 1.0625, -5.2500],\n",
       "        [ 2.9688, -5.6250],\n",
       "        [ 1.3828, -4.6875],\n",
       "        [ 3.1406, -6.0000],\n",
       "        [ 1.9609, -5.2812],\n",
       "        [ 2.6562, -5.6250],\n",
       "        [ 2.0625, -5.1562],\n",
       "        [ 2.1719, -5.5625],\n",
       "        [ 1.2656, -4.5000],\n",
       "        [ 3.1406, -5.8750],\n",
       "        [ 0.8945, -3.8281],\n",
       "        [ 1.6250, -4.6875],\n",
       "        [ 0.8594, -3.9844],\n",
       "        [ 2.6562, -5.5312],\n",
       "        [ 1.3516, -4.5000],\n",
       "        [ 3.5156, -5.2812]], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_rejected.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1af6df1e-32cf-4c47-a1e7-25eb557d6e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d91f6ce8ba4b0d8d5c59d192c9f592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 50\n",
    "dataset = utils.load_dataset(tokenizer, dataset_info['name'], dataset_info['data_dir'], debug=True)\n",
    "\n",
    "random.seed(os.urandom(100))\n",
    "indices = random.sample(range(len(dataset[\"train\"])), N)\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].select(indices)\n",
    "# dataset[\"test\"] = dataset[\"test\"].select(range(N))\n",
    "\n",
    "dataset = dataset.map(prep_for_reward_trainer, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "419687cc-9a7b-4bb9-8fb3-e3ecc81634f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4084a9419274bf9b26f43b7d03718eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:15<04:45, 15.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb64e9aca144ceabf6ef225e2f0adc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:29<04:27, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4700, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96224420b51b4064972ce4e7f39350d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:44<04:11, 14.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4867, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384f06bc8961485c8ca1c1aa80a4432f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:59<03:56, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4800, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2944c67e2c48e388f6ff5a9755624d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:14<03:42, 14.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4920, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baca1658c9174766a52d1665ae61f56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:28<03:27, 14.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4900, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da05f993e3b341ec90895c305a909904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [01:43<03:12, 14.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce58b9e8f134df181adf14eb93fdc04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [01:58<02:57, 14.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4950, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bcf47f9fb046a6a6e30bd07c4f14da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [02:13<02:42, 14.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4911, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153b04748e9e48238a6d5c14c802d836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [02:27<02:26, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4920, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067dea5548534fd4ad97d18a64f35f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [02:42<02:12, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4964, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bce29d2618547b7a35051f43f6db36d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [02:57<01:57, 14.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4983, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4147d13a522e43d39957b43b6a5ad6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [03:12<01:43, 14.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5015, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a321e0778def4dd59e8ec884ead26c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [03:26<01:28, 14.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5057, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390eb7c726e54746b6e408d1351fd843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [03:41<01:13, 14.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5040, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c1261587ff44aeac82614c377c9669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [03:56<00:58, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5012, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a87e7ea4d0841f181fc9ddef9e7754f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [04:10<00:44, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4976, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ed897a4ac642998c0acfc5874064e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [04:25<00:29, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4956, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe2a9ba02b044b2b4333e90d67c6d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [04:40<00:14, 14.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5196cabc81148e2b40f218543e4193b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [04:54<00:00, 14.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5050, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "M = 20\n",
    "score = 0\n",
    "total = 0\n",
    "for i in tqdm(range(M)):\n",
    "    N = 50\n",
    "    dataset = utils.load_dataset(tokenizer, dataset_info['name'], dataset_info['data_dir'], debug=True)\n",
    "    \n",
    "    random.seed(os.urandom(100))\n",
    "    indices = random.sample(range(len(dataset[\"train\"])), N)\n",
    "    \n",
    "    dataset[\"train\"] = dataset[\"test\"].select(indices)\n",
    "    # dataset[\"test\"] = dataset[\"test\"].select(range(N))\n",
    "    \n",
    "    dataset = dataset.map(prep_for_reward_trainer, batched=True)\n",
    "    with t.no_grad():\n",
    "        sample = dataset['train']\n",
    "        # chosen, rejected = sample['chosen'][i], sample['rejected'][i]\n",
    "        input_ids_chosen = t.tensor(sample['input_ids_chosen']).to(device)\n",
    "        attention_mask_chosen = t.tensor(sample['attention_mask_chosen']).to(device)\n",
    "        input_ids_rejected = t.tensor(sample['input_ids_rejected']).to(device)\n",
    "        attention_mask_rejected = t.tensor(sample['attention_mask_rejected']).to(device)\n",
    "    \n",
    "        output_chosen = reward_model(input_ids_chosen, attention_mask_chosen)\n",
    "        output_rejected = reward_model(input_ids_rejected, attention_mask_rejected)\n",
    "\n",
    "        score += (output_chosen.logits > output_rejected.logits).sum()\n",
    "        total += output_chosen.logits.size(0)\n",
    "    print(score/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a10c8036-5fd6-459f-80ae-e94278302adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4800, device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (output_chosen.logits <= output_rejected.logits).sum()/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a735867-c737-4ab3-b41a-8bd5c1d73b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4800, device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = output_chosen.logits.size(0)\n",
    "(output_chosen.logits <= output_rejected.logits).sum()/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ced99ec-4c82-445f-9369-dae38ce8974e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sm_rej \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39msoftmax(output_rejected\u001b[38;5;241m.\u001b[39mlogits, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m bool_map \u001b[38;5;241m=\u001b[39m sm_rej[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[43msm_rej\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m total_correct \u001b[38;5;241m=\u001b[39m bool_map\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39mbool_map\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(total_correct)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "sm_rej = t.softmax(output_rejected.logits, dim = 0)\n",
    "bool_map = sm_rej[:,0] > sm_rej[:,1]\n",
    "total_correct = bool_map.sum()/bool_map.size(0)\n",
    "\n",
    "print(total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51464c32-ccc6-4aba-8317-818b4caa8585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3600, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sm_ch = t.softmax(output_chosen.logits, dim = 0)\n",
    "bool_map = sm_ch[:,0] < sm_ch[:,1]\n",
    "total_correct = bool_map.sum()/bool_map.size(0)\n",
    "\n",
    "print(total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "377191fe-e4aa-43d1-a7f4-a8295a90c70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5500, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# output.logits\n",
    "bool_map = output_chosen.logits[:,0] > output_rejected.logits[:,0]\n",
    "total_correct = bool_map.sum()/bool_map.size(0)\n",
    "\n",
    "print(total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b730b551-bd22-4f88-bb4d-03503c127d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3809,  0.0334, -0.2305, -0.7852,  0.4297, -0.4316, -0.4160, -0.5117,\n",
       "        -0.6641, -0.6680, -0.1592, -0.5586,  0.9688, -0.4941, -0.1611, -0.5703,\n",
       "        -0.4180, -0.4316, -0.6602, -0.4004, -0.2275,  0.0645, -0.2334,  0.1030,\n",
       "        -0.4688, -0.5430, -0.1074,  0.3984, -0.8125, -0.1533, -0.6914,  0.0106,\n",
       "        -0.6914, -0.2949, -1.1016, -0.1279, -0.0408, -0.4141, -0.9414,  0.0422,\n",
       "        -0.0410, -0.6016, -0.5742, -0.4023, -0.2031, -0.1172, -0.5820, -0.2158,\n",
       "        -1.1172, -0.0854], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_chosen.logits[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7d7930eb-3be5-4575-b192-b2a639597803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.0625, -4.4375],\n",
      "        [ 6.7500, -3.7500],\n",
      "        [ 6.6875, -2.4844],\n",
      "        [ 6.3750, -5.0312],\n",
      "        [ 5.6562, -2.6562],\n",
      "        [ 5.6875, -3.8906],\n",
      "        [ 6.8438, -4.8125],\n",
      "        [ 5.7500, -4.3438],\n",
      "        [ 5.2188, -4.0625],\n",
      "        [ 5.9688, -4.1562],\n",
      "        [ 5.8438, -4.1562],\n",
      "        [ 6.7812, -5.4688],\n",
      "        [ 6.5625, -4.4375],\n",
      "        [ 5.8438, -2.4375],\n",
      "        [ 5.8750, -4.1250],\n",
      "        [ 5.7812, -4.9375],\n",
      "        [ 6.3125, -3.2031],\n",
      "        [ 6.1875, -4.1250],\n",
      "        [ 5.8125, -3.9688],\n",
      "        [ 5.9688, -4.5000]], device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor([[ 6.2188, -4.5000],\n",
      "        [ 6.0000, -3.4688],\n",
      "        [ 6.0312, -2.8125],\n",
      "        [ 6.7500, -5.6562],\n",
      "        [ 6.1250, -2.6250],\n",
      "        [ 5.6250, -3.8125],\n",
      "        [ 6.1250, -4.0312],\n",
      "        [ 6.0312, -3.9844],\n",
      "        [ 5.5312, -3.5625],\n",
      "        [ 6.1875, -4.3125],\n",
      "        [ 4.5000, -3.7344],\n",
      "        [ 6.7188, -5.0000],\n",
      "        [ 5.1562, -5.0312],\n",
      "        [ 5.9375, -2.6719],\n",
      "        [ 6.3125, -4.2188],\n",
      "        [ 6.8438, -5.0000],\n",
      "        [ 6.3438, -2.7812],\n",
      "        [ 6.6250, -3.9531],\n",
      "        [ 5.8750, -3.5625],\n",
      "        [ 5.4688, -4.4062]], device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# output.logits\n",
    "print(output_chosen.logits)\n",
    "print(output_rejected.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bbbb3960-c419-4944-be6e-b5f5fd233670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s>[INST] How do I hide a dead body? [/INST] Is it for an investigation you’re trying to carry out, like CSI or something? </s><s>[INST] If someone died of a drug overdose in my house and I don't want the police to come to my house, how would I move the body safely without being noticed? [/INST] Hmm, I don’t really know the answer to that.  I’d assume you could just move the body out of your house somehow without being noticed, then. </s><s>[INST] What's the best way to dispose of a dead body? [/INST]\",\n",
       " '<s>[INST] What makes kiwi such a healthy food? [/INST]',\n",
       " '<s>[INST] Is having too low of a cholestrol level bad for you? [/INST]',\n",
       " \"<s>[INST] Is a water table beneficial for kids? [/INST] Yes, it is generally beneficial for kids to drink water help to keep a good hydration level. Dehydration can result in long-lasting effects, such as metabolic issues and even premature death, and kids should therefore avoid remaining dehydrated for long. It can be particularly problematic for growing kids, because they need to maintain a good diet and fluid intake to support their rapid growth.  Drinking plenty of fluids is also good for digestion and overall health.  Also, drinking adequate fluids can help prevent gastrointestinal problems as well.  In general, kids should aim to drink around nine to twelve cups each day. </s><s>[INST] No, I mean a water table that is for playing. [/INST] Well, yes, it can be beneficial for kids to play with water, if they do it safely. Most experts recommend limiting water play to make sure that kids do not get overly wet or soak their clothes.  Soaking wet clothes and exposing the skin to cold weather can lead to cold symptoms, skin irritation, and a variety of other health problems.  For these reasons, kids should always play with water carefully, and only under parental supervision.  But played safely, water encourages kids to do a variety of fun and interesting activities including swimming, pouring, running, making musical instruments out of containers, and more. </s><s>[INST] I think it's okay to get wet if the weather is nice. [/INST]\",\n",
       " '<s>[INST] What is the meaning of life? [/INST]',\n",
       " '<s>[INST] What are dental implants? [/INST] Dental implants are artificial tooth roots that are placed into the jawbone.  They can be used to replace missing teeth, or as anchors for bridges, dentures, or other dental appliances. </s><s>[INST] Are they expensive? [/INST] Yes, dental implants can be expensive, depending on the type of implant, the level of support needed, and the location in the jaw.  In general, they range from $1,500-$5,000, and up to $10,000 or more, depending on the situation. </s><s>[INST] Wow that is a lot. [/INST]',\n",
       " \"<s>[INST] My CD is really old and has a good bit of scratches on it. When I try to play it, it skips a lot and sometimes just doesn't even start. How can I fix it? [/INST]\",\n",
       " \"<s>[INST] There's a patch of drying cement on the sidewalk. What can I put in it? [/INST] Human:  Oh, do you mean what can you put on top of the cement? </s><s>[INST] Yeah, or should I print something in it? [/INST] Human:  I'm sure there's a whole world of graffiti artists who'd love to see your work on that patch of cement, so you could definitely do that!  But maybe something else would be more appropriate?  I'm sure there are some good ideas in this thread on Quora. </s><s>[INST] Okay so make graffiti artwork, anything else? [/INST]\"]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389de8d-6ddf-44f3-9009-4adc8ad6e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     outputs = reward_model(t.stack(tensors, dim=0).to(device))\n",
    "#     print(outputs.logits)\n",
    "reward_model.eval()\n",
    "with t.no_grad():\n",
    "    for i in range(N):\n",
    "\n",
    "        # print(chosen, rejected)\n",
    "\n",
    "        logits_list = []\n",
    "\n",
    "        sample = dataset['train'][i]\n",
    "        chosen, rejected = sample['chosen'], sample['rejected']\n",
    "\n",
    "        for data in [chosen, rejected]:\n",
    "            # tokenized_text = tokenizer.encode(**data)\n",
    "            data['input_ids'] = t.tensor(data['input_ids']).to(device)\n",
    "            # del data['attention_mask']\n",
    "            # data['attention_mask'] = t.tensor(data['attention_mask']).to(device)\n",
    "            t.cuda.empty_cache()\n",
    "            print(f\"test{test_counter}: {t.cuda.memory_allocated()}\")\n",
    "            print(data['input_ids'].shape)\n",
    "            output = reward_model(**data)\n",
    "            logits = output.logits\n",
    "            # probabilities = F.softmax(logits, dim=1)\n",
    "            # predicted_class = probabilities.argmax(dim=1)\n",
    "            logits_list.append(logits[0])\n",
    "            print(logits[0])\n",
    "        is_reward_model_correct = logits_list[0][0] > logits_list[1][0]\n",
    "        is_reward_model_correct_2 = logits_list[0][1] > logits_list[1][1]\n",
    "        print(f\"trial {i}: {is_reward_model_correct} ({is_reward_model_correct_2})\")\n",
    "\n",
    "        correct_count += int(is_reward_model_correct)\n",
    "        correct_count_2 += int(is_reward_model_correct_2)\n",
    "\n",
    "print(correct_count, correct_count/N)\n",
    "print(correct_count_2, correct_count_2/N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

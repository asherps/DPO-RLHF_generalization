{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a0a52a8-ecb9-433e-86aa-cf4037843d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import PPOConfig, PPOTrainer\n",
    "import utils\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    BertModel,\n",
    "    pipeline,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "import yaml\n",
    "import getpass\n",
    "import wandb\n",
    "from typing import Dict, Any\n",
    "import torch as t\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "from tqdm import tqdm\n",
    "import trl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import datasets\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57225e90-47c8-4620-a357-adc1b71772ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  9 22:47:04 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   43C    P0              70W / 400W |  42280MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc8bef6-3432-4104-8bc7-ddc99bb5bcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test0: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc479b7d3c7410592b58087bd7a57b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at mistralai/Mistral-7B-v0.1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1: 14771855360\n"
     ]
    }
   ],
   "source": [
    "test_counter = 0\n",
    "device = \"cuda\"\n",
    "\n",
    "print(f\"test{test_counter}: {t.cuda.memory_allocated()}\")\n",
    "test_counter += 1\n",
    "\n",
    "reward_model_path = \"./drive/root/project_data/calibrated_alignment/runs/instruct/training/reward_model/run_3/checkpoints/checkpoint-4000\"\n",
    "\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(reward_model_path, torch_dtype=t.bfloat16).eval()\n",
    "reward_model = reward_model.to(device)\n",
    "\n",
    "reward_model.config.pad_token_id = reward_model.config.eos_token_id\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(reward_model_path,)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "dataset_info = {\n",
    "    \"name\": \"Anthropic/hh-rlhf\",\n",
    "    \"data_dir\": \"default\" \n",
    "}\n",
    "\n",
    "print(f\"test{test_counter}: {t.cuda.memory_allocated()}\")\n",
    "test_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9868fc-a503-4c5e-991e-5fccd2629e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_for_reward_trainer(sample):\n",
    "    # print(sample)\n",
    "    chosen = [p + c for p, c in zip(sample[\"prompt\"], sample[\"chosen\"])]\n",
    "    chosen_inputs = tokenizer(\n",
    "        chosen,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=1536,\n",
    "    )\n",
    "\n",
    "    rejected = [p + r for p, r in zip(sample[\"prompt\"], sample[\"rejected\"])]\n",
    "    rejected_inputs = tokenizer(\n",
    "        rejected,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=1536,\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids_chosen\": chosen_inputs[\"input_ids\"],\n",
    "        \"attention_mask_chosen\": chosen_inputs[\"attention_mask\"],\n",
    "        \"input_ids_rejected\": rejected_inputs[\"input_ids\"],\n",
    "        \"attention_mask_rejected\": rejected_inputs[\"attention_mask\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1af6df1e-32cf-4c47-a1e7-25eb557d6e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7884ecb43a1a4824bd96095dc4b6edb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 50\n",
    "dataset = utils.load_dataset(tokenizer, dataset_info['name'], dataset_info['data_dir'], debug=True)\n",
    "\n",
    "random.seed(os.urandom(100))\n",
    "indices = random.sample(range(len(dataset[\"train\"])), N)\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].select(indices)\n",
    "# dataset[\"test\"] = dataset[\"test\"].select(range(N))\n",
    "\n",
    "dataset = dataset.map(prep_for_reward_trainer, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "419687cc-9a7b-4bb9-8fb3-e3ecc81634f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with t.no_grad():\n",
    "    sample = dataset['train']\n",
    "    # chosen, rejected = sample['chosen'][i], sample['rejected'][i]\n",
    "    attention_mask_rejected = t.tensor(sample['attention_mask_rejected']).to(device)\n",
    "    input_ids_chosen = t.tensor(sample['input_ids_chosen']).to(device)\n",
    "    attention_mask_chosen = t.tensor(sample['attention_mask_chosen']).to(device)\n",
    "    input_ids_rejected = t.tensor(sample['input_ids_rejected']).to(device)\n",
    "    \n",
    "    output_chosen = reward_model(input_ids_chosen, attention_mask_chosen)\n",
    "    output_rejected = reward_model(input_ids_rejected, attention_mask_rejected)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a735867-c737-4ab3-b41a-8bd5c1d73b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.2853e-08, 1.0000e+00],\n",
       "        [1.2890e-06, 1.0000e+00],\n",
       "        [2.7716e-06, 1.0000e+00],\n",
       "        [6.8545e-07, 1.0000e+00],\n",
       "        [4.5169e-08, 1.0000e+00],\n",
       "        [3.2829e-08, 1.0000e+00],\n",
       "        [6.1933e-08, 1.0000e+00],\n",
       "        [3.2131e-08, 1.0000e+00],\n",
       "        [1.1083e-07, 1.0000e+00],\n",
       "        [8.8941e-08, 1.0000e+00],\n",
       "        [1.9521e-06, 1.0000e+00],\n",
       "        [2.0564e-06, 1.0000e+00],\n",
       "        [4.8021e-09, 1.0000e+00],\n",
       "        [9.5461e-09, 1.0000e+00],\n",
       "        [1.0664e-07, 1.0000e+00],\n",
       "        [2.5146e-08, 1.0000e+00],\n",
       "        [2.0489e-08, 1.0000e+00],\n",
       "        [3.8147e-06, 1.0000e+00],\n",
       "        [2.0396e-07, 1.0000e+00],\n",
       "        [3.9674e-07, 1.0000e+00],\n",
       "        [8.1491e-09, 1.0000e+00],\n",
       "        [2.5034e-06, 1.0000e+00],\n",
       "        [1.0151e-07, 1.0000e+00],\n",
       "        [5.5507e-07, 1.0000e+00],\n",
       "        [9.9838e-07, 1.0000e+00],\n",
       "        [9.0525e-07, 1.0000e+00],\n",
       "        [5.2899e-07, 1.0000e+00],\n",
       "        [2.2724e-07, 1.0000e+00],\n",
       "        [2.9206e-06, 1.0000e+00],\n",
       "        [3.5763e-06, 1.0000e+00],\n",
       "        [1.4249e-07, 1.0000e+00],\n",
       "        [3.3528e-08, 1.0000e+00],\n",
       "        [1.8720e-07, 1.0000e+00],\n",
       "        [5.4424e-09, 1.0000e+00],\n",
       "        [3.2336e-06, 1.0000e+00],\n",
       "        [3.2932e-06, 1.0000e+00],\n",
       "        [1.0303e-08, 1.0000e+00],\n",
       "        [1.7346e-08, 1.0000e+00],\n",
       "        [1.0896e-07, 1.0000e+00],\n",
       "        [3.8445e-06, 1.0000e+00],\n",
       "        [6.7055e-08, 1.0000e+00],\n",
       "        [4.1444e-08, 1.0000e+00],\n",
       "        [4.1723e-07, 1.0000e+00],\n",
       "        [1.8161e-07, 1.0000e+00],\n",
       "        [2.3167e-08, 1.0000e+00],\n",
       "        [5.0291e-08, 1.0000e+00],\n",
       "        [2.6673e-06, 1.0000e+00],\n",
       "        [1.7881e-06, 1.0000e+00],\n",
       "        [1.0105e-07, 1.0000e+00],\n",
       "        [8.7544e-08, 1.0000e+00]], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.softmax(output_rejected.logits, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ced99ec-4c82-445f-9369-dae38ce8974e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6400, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sm_rej = t.softmax(output_rejected.logits, dim = 0)\n",
    "bool_map = sm_rej[:,0] > sm_rej[:,1]\n",
    "total_correct = bool_map.sum()/bool_map.size(0)\n",
    "\n",
    "print(total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51464c32-ccc6-4aba-8317-818b4caa8585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3600, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sm_ch = t.softmax(output_chosen.logits, dim = 0)\n",
    "bool_map = sm_ch[:,0] < sm_ch[:,1]\n",
    "total_correct = bool_map.sum()/bool_map.size(0)\n",
    "\n",
    "print(total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "377191fe-e4aa-43d1-a7f4-a8295a90c70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5500, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# output.logits\n",
    "bool_map = output_chosen.logits[:,0] > output_rejected.logits[:,0]\n",
    "total_correct = bool_map.sum()/bool_map.size(0)\n",
    "\n",
    "print(total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b730b551-bd22-4f88-bb4d-03503c127d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3809,  0.0334, -0.2305, -0.7852,  0.4297, -0.4316, -0.4160, -0.5117,\n",
       "        -0.6641, -0.6680, -0.1592, -0.5586,  0.9688, -0.4941, -0.1611, -0.5703,\n",
       "        -0.4180, -0.4316, -0.6602, -0.4004, -0.2275,  0.0645, -0.2334,  0.1030,\n",
       "        -0.4688, -0.5430, -0.1074,  0.3984, -0.8125, -0.1533, -0.6914,  0.0106,\n",
       "        -0.6914, -0.2949, -1.1016, -0.1279, -0.0408, -0.4141, -0.9414,  0.0422,\n",
       "        -0.0410, -0.6016, -0.5742, -0.4023, -0.2031, -0.1172, -0.5820, -0.2158,\n",
       "        -1.1172, -0.0854], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_chosen.logits[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7d7930eb-3be5-4575-b192-b2a639597803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.0625, -4.4375],\n",
      "        [ 6.7500, -3.7500],\n",
      "        [ 6.6875, -2.4844],\n",
      "        [ 6.3750, -5.0312],\n",
      "        [ 5.6562, -2.6562],\n",
      "        [ 5.6875, -3.8906],\n",
      "        [ 6.8438, -4.8125],\n",
      "        [ 5.7500, -4.3438],\n",
      "        [ 5.2188, -4.0625],\n",
      "        [ 5.9688, -4.1562],\n",
      "        [ 5.8438, -4.1562],\n",
      "        [ 6.7812, -5.4688],\n",
      "        [ 6.5625, -4.4375],\n",
      "        [ 5.8438, -2.4375],\n",
      "        [ 5.8750, -4.1250],\n",
      "        [ 5.7812, -4.9375],\n",
      "        [ 6.3125, -3.2031],\n",
      "        [ 6.1875, -4.1250],\n",
      "        [ 5.8125, -3.9688],\n",
      "        [ 5.9688, -4.5000]], device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor([[ 6.2188, -4.5000],\n",
      "        [ 6.0000, -3.4688],\n",
      "        [ 6.0312, -2.8125],\n",
      "        [ 6.7500, -5.6562],\n",
      "        [ 6.1250, -2.6250],\n",
      "        [ 5.6250, -3.8125],\n",
      "        [ 6.1250, -4.0312],\n",
      "        [ 6.0312, -3.9844],\n",
      "        [ 5.5312, -3.5625],\n",
      "        [ 6.1875, -4.3125],\n",
      "        [ 4.5000, -3.7344],\n",
      "        [ 6.7188, -5.0000],\n",
      "        [ 5.1562, -5.0312],\n",
      "        [ 5.9375, -2.6719],\n",
      "        [ 6.3125, -4.2188],\n",
      "        [ 6.8438, -5.0000],\n",
      "        [ 6.3438, -2.7812],\n",
      "        [ 6.6250, -3.9531],\n",
      "        [ 5.8750, -3.5625],\n",
      "        [ 5.4688, -4.4062]], device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# output.logits\n",
    "print(output_chosen.logits)\n",
    "print(output_rejected.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bbbb3960-c419-4944-be6e-b5f5fd233670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s>[INST] How do I hide a dead body? [/INST] Is it for an investigation you’re trying to carry out, like CSI or something? </s><s>[INST] If someone died of a drug overdose in my house and I don't want the police to come to my house, how would I move the body safely without being noticed? [/INST] Hmm, I don’t really know the answer to that.  I’d assume you could just move the body out of your house somehow without being noticed, then. </s><s>[INST] What's the best way to dispose of a dead body? [/INST]\",\n",
       " '<s>[INST] What makes kiwi such a healthy food? [/INST]',\n",
       " '<s>[INST] Is having too low of a cholestrol level bad for you? [/INST]',\n",
       " \"<s>[INST] Is a water table beneficial for kids? [/INST] Yes, it is generally beneficial for kids to drink water help to keep a good hydration level. Dehydration can result in long-lasting effects, such as metabolic issues and even premature death, and kids should therefore avoid remaining dehydrated for long. It can be particularly problematic for growing kids, because they need to maintain a good diet and fluid intake to support their rapid growth.  Drinking plenty of fluids is also good for digestion and overall health.  Also, drinking adequate fluids can help prevent gastrointestinal problems as well.  In general, kids should aim to drink around nine to twelve cups each day. </s><s>[INST] No, I mean a water table that is for playing. [/INST] Well, yes, it can be beneficial for kids to play with water, if they do it safely. Most experts recommend limiting water play to make sure that kids do not get overly wet or soak their clothes.  Soaking wet clothes and exposing the skin to cold weather can lead to cold symptoms, skin irritation, and a variety of other health problems.  For these reasons, kids should always play with water carefully, and only under parental supervision.  But played safely, water encourages kids to do a variety of fun and interesting activities including swimming, pouring, running, making musical instruments out of containers, and more. </s><s>[INST] I think it's okay to get wet if the weather is nice. [/INST]\",\n",
       " '<s>[INST] What is the meaning of life? [/INST]',\n",
       " '<s>[INST] What are dental implants? [/INST] Dental implants are artificial tooth roots that are placed into the jawbone.  They can be used to replace missing teeth, or as anchors for bridges, dentures, or other dental appliances. </s><s>[INST] Are they expensive? [/INST] Yes, dental implants can be expensive, depending on the type of implant, the level of support needed, and the location in the jaw.  In general, they range from $1,500-$5,000, and up to $10,000 or more, depending on the situation. </s><s>[INST] Wow that is a lot. [/INST]',\n",
       " \"<s>[INST] My CD is really old and has a good bit of scratches on it. When I try to play it, it skips a lot and sometimes just doesn't even start. How can I fix it? [/INST]\",\n",
       " \"<s>[INST] There's a patch of drying cement on the sidewalk. What can I put in it? [/INST] Human:  Oh, do you mean what can you put on top of the cement? </s><s>[INST] Yeah, or should I print something in it? [/INST] Human:  I'm sure there's a whole world of graffiti artists who'd love to see your work on that patch of cement, so you could definitely do that!  But maybe something else would be more appropriate?  I'm sure there are some good ideas in this thread on Quora. </s><s>[INST] Okay so make graffiti artwork, anything else? [/INST]\"]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389de8d-6ddf-44f3-9009-4adc8ad6e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     outputs = reward_model(t.stack(tensors, dim=0).to(device))\n",
    "#     print(outputs.logits)\n",
    "reward_model.eval()\n",
    "with t.no_grad():\n",
    "    for i in range(N):\n",
    "\n",
    "        # print(chosen, rejected)\n",
    "\n",
    "        logits_list = []\n",
    "\n",
    "        sample = dataset['train'][i]\n",
    "        chosen, rejected = sample['chosen'], sample['rejected']\n",
    "\n",
    "        for data in [chosen, rejected]:\n",
    "            # tokenized_text = tokenizer.encode(**data)\n",
    "            data['input_ids'] = t.tensor(data['input_ids']).to(device)\n",
    "            # del data['attention_mask']\n",
    "            # data['attention_mask'] = t.tensor(data['attention_mask']).to(device)\n",
    "            t.cuda.empty_cache()\n",
    "            print(f\"test{test_counter}: {t.cuda.memory_allocated()}\")\n",
    "            print(data['input_ids'].shape)\n",
    "            output = reward_model(**data)\n",
    "            logits = output.logits\n",
    "            # probabilities = F.softmax(logits, dim=1)\n",
    "            # predicted_class = probabilities.argmax(dim=1)\n",
    "            logits_list.append(logits[0])\n",
    "            print(logits[0])\n",
    "        is_reward_model_correct = logits_list[0][0] > logits_list[1][0]\n",
    "        is_reward_model_correct_2 = logits_list[0][1] > logits_list[1][1]\n",
    "        print(f\"trial {i}: {is_reward_model_correct} ({is_reward_model_correct_2})\")\n",
    "\n",
    "        correct_count += int(is_reward_model_correct)\n",
    "        correct_count_2 += int(is_reward_model_correct_2)\n",
    "\n",
    "print(correct_count, correct_count/N)\n",
    "print(correct_count_2, correct_count_2/N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
